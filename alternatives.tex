\section{***Alternative Models Using Sets of Priors}
\label{sec:alternatives}


In Section~\ref{sec:generalmodel},
we have discussed a specific class of models based on parametrically constructed sets of conjugate priors,
and illustrated the main ideas and potential of generalised Bayesian inference for this model framework.

Now, we will briefly discuss some further approaches that could serve
as an alternative to the sets of conjugate priors discussed in this thesis.
Firstly, in Section~\ref{sec:alternatives:conjugate} we will describe some models
that also rely on conjugate priors in exponential families,
but that cannot be subsumed in the framework of Section~\ref{sec:generalmodel}.
In Section~\ref{sec:alternatives:other}, we will touch on models based on sets of priors that do not rely on conjugates.

There are models in both sections*** where, 
instead of generating the set of prior distributions by varying their parameters in a set
(as in Section~\ref{sec:generalmodel}),
the set of priors $\mathcal{M}$ is defined as an \emph{interval of measures},
also known as \emph{density-ratio class}
%Another interesting model that could be considered
%as an alternative to the sets of conjugate priors discussed in this thesis
%is the \emph{density-ratio class} model,
%also known as \emph{interval of measures}
\parencites{1981:derobertis}{1990:berger}.%
\footnote{\label{foot:rinderknecht}A very accessible presentation of density-ratio classes with
parametric bounding shapes $l(\vartheta)$ and $u(\vartheta)$,
along with a method for elicition from an expert
providing quantiles (or quantile ranges) for a number of probability values,
is given in \textcite{2011:rinderknecht}.}
Here, a set of (prior) distributions on $\vartheta$ is defined by %$\mathcal{M}_{l,u}$ by 
%through restricting the densities $p(\vartheta)$ in $\mathcal{M}_{l,u}$ to
\begin{align}\label{eq:densityratioclass}
\mathcal{M}_{l,u} = \left\{ p(\vartheta) :
\exists c \in \posreals: l(\vartheta) \le c p(\vartheta) \le u(\vartheta)\right\}\,,
\end{align}
where $l(\vartheta)$ and $u(\vartheta)$ are bounded non-negative functions (i.e., non-normalised densities)	
for which $l(\vartheta) \le u(\vartheta)\ \forall\ \vartheta$.
$l(\vartheta)$ and $u(\vartheta)$ are often called \emph{lower and upper density functions},
and only need to be known up to a multiplicative constant.
If $l(\vartheta)>0\ \forall\ \vartheta$, then \eqref{eq:densityratioclass} can also be written as
\begin{align*}
\mathcal{M}_{l,u} = \left\{ p(\cdot) :
\frac{p(\vartheta)}{p(\vartheta')} \le \frac{u(\vartheta)}{l(\vartheta')}\ \forall\ \vartheta, \vartheta' \right\}\,,
\end{align*}
hence the name `density ration class'.

The density ratio class thus can be seen as a certain type of credal sets as discussed in Section~\ref{sec:ip-main},
%(derived from generic lower previsions)
%\parencite[Figure~5.5]{itip-special},
with the convenient property of invariance under Bayesian updating,
i.e., the set of posteriors derived from $\mathcal{M}_{l,u}$
through the Generalised Bayes' Rule (i.e., by updating element by element,
see Sections~\ref{sec:gbr} and \ref{sec:imprecisebayes})
can again be expressed as a density ratio class,
with $l(\vartheta)$ and $u(\vartheta)$ updated according to Bayes' Rule \parencite{1981:derobertis}.
The density ration class has further advantageous properties,
especially as compared to the neighbourhood models described in Section~\ref{sec:alternatives:other}
\parencite[see, e.g.,][\S 2.3]{2011:rinderknecht}.

It is important to note here that even if the bounding functions $l(\vartheta)$ and $u(\vartheta)$ are defined parametrically
(or, as in the approaches by Coolen \parencite*{1993:coolen, 1994:coolen} described below, as conjugates),
$\mathcal{M}_{l,u}$ does not contain only these parametric densities (or conjugate densities).
Instead, $\mathcal{M}_{l,u}$ contains a variety of shapes, where
(if $l(\vartheta)$ and $u(\vartheta)$ are not proportional)
the tail behaviour can vary between that of $l(\vartheta)$ and $u(\vartheta)$
\parencite[\S 3.2]{2011:rinderknecht}.

The density ratio class is thus similar to sets of priors
discussed in the model framework from Section~\ref{sec:basicsetting} where
$\MZ$ is taken as all convex mixtures of parametric priors with parameters in $\PZ$.
Then, also $\MZ$ contains a variety of shapes that, however,
do not allow for substantially different tail behaviour,
and it still has the same property of invariance under Bayesian updating,
because $\MN$ can be constructed as the set of all convex mixtures of distributions with parameters in $\PN$.



\subsection{Approaches Based on Conjugate Priors}
\label{sec:alternatives:conjugate}

%first sets based on conjugate priors: %1993:coolen, 1994:coolen interval of measures:
%2011:rinderknecht does not consider update step, just elicitation, but 2011:rinderknecht:phd does
%then 2009:bickis

\textcite{1993:coolen} proposed an interesting model for sample distributions
from the one-parameter exponential family using the density ration class.
In this model, the prior bounding functions $l(\vartheta)$ and $u(\vartheta)$ from \eqref{eq:densityratioclass}
are linked through the relation $u(\vartheta) = c_0 \cdot l(\vartheta)$,
where $c_0 \ge 1$ is independent of $\vartheta$.
Defining $l(\vartheta\mid\pz)$ as (proportional to) the conjugate prior, with hyperparmeter $\pz$,
calculation of the posterior lower bounding function $l(\vartheta\mid\x,\pz)$ is straight-forward, by%
\footnote{Remember that $l(\cdot)$ needs to be known up to a multiplicative constant only.}
\begin{align*}
l(\vartheta\mid\x,\pz) &= l(\vartheta\mid\pz) f(\x\mid\vartheta) = l(\vartheta\mid\pn)\,,
%\end{align*}
\intertext{and the posterior upper bounding function is defined as}
%\begin{align*}
u(\vartheta\mid\x,\pz) &:= \frac{c_n}{c_0} u(\vartheta\mid\pz) f(\x\mid\vartheta) = c_n l(\vartheta\mid\pn)\,,
\end{align*}
where $c_n$ is introduced to allow the posterior imprecision to decrease in dependence of the samples size $n$.%
\footnote{$c_n \neq c_0$ means that we actually do not update $\mathcal{M}$ according to the Generalised Bayes' Rule.}
$c_n$ must thus be chosen as a function decreasing in $n$,
and \textcite{1993:coolen} suggests a functional form with
$c_n \to 1$ for $n \to \infty$, containing a parameter $\xi$
that has a meaning similar to $\nz$, in the sense that if $n = \xi$,
an information measure suggested by \textcite[\S 5.3.7]{1991:walley} is doubled.%
\footnote{Imprecision for models with fixed $\nz$ (Section~\ref{sec:basicsetting}, item~\ref{enum:modeltypes-a})
is halfed when $\nz = n$, see Section~\ref{sec:gbicp-properties-criteria}, item~\ref{enum:n0vsn}.}
To use the model, one has to elicit thus the parameter(s) of the conjugate prior $\pz$,
along with $c_0$ and $\xi$.
The model is quite easy to handle as the density ratio class provides relatively simple formulas for, e.g.,
lower and upper cumulative density functions, and lower and upper predictive densities.
These formulas are easy to calculate if the involved integrals are easy to obtain,
as is the case for a conjugate choice of $l(\vartheta)$.
However, this model is insensitive to \pdc, owing to the requirement of $c_0$ and $c_n$
to be independent of $\theta$ and $\x$ (except for the sample size $n$);
furthermore, there could be many other functional forms for $c_n$ that are equally reasonable
as the one suggested in the paper \parencite[p.~341]{1993:coolen}.

\medskip

\textcite{1994:coolen} presents a further study of this model
for the special case of Bernoulli observations, and with a focus on predictive inferences.
There, $l(\theta)$ is proportional to a $\be(\alpha,\beta)$,
and $u(\theta)$ is defined as
\begin{align*}
u(\theta) = l(\theta) + c^*_0 \cdot a(\theta)\,,
\end{align*}
where $a(\theta)$ is proportional to a $\be(\mu,\lambda)$,
and $c^*_0$ is again a factor that determines the prior imprecision.
For the case $\mu=\alpha$, $\beta=\lambda$, and $c^*_0 = c^*_n = c$ for all $n$,%
\footnote{The relation between $c_0$ and $c^*_0$ is thus $c^*_0 = c_0 - 1$.}
formulas are derived that allow to study
imprecision in posterior predicitive probabilities analytically.
This model gives interesting insights into the dependence of imprecision on $s$,
but the fact that posterior imprecision is the very same as prior imprecision
if $s/n = \alpha/(\alpha+\beta)$ (i.e., data and prior assignments are perfectly in line)
suggests that this model is not suitable for inferences \parencite[p.~160]{1994:coolen}.
Furthermore, our conjecture is that the influence of $s$ on posterior imprecision
is due to the restriction that the two bounding functions have to be
proportional to Beta densities. For the case of $s/n = \alpha/(\alpha+\beta)$,
imprecision decreases for any $s \neq n/2$ \parencite[Table~1]{1994:coolen}.
This is very similar to the phenomenon that, in the Multinomial-Dirichlet model,
the posterior variance of $\theta_j$ decreases for any $n_j$ if $\yz_j = 1/2$
(see Section~\ref{sec:ex-mult}).

Afterwards, the general case with $\mu\neq\alpha$, $\beta\neq\lambda$, and $c^*_n$ as in \textcite{1993:coolen}
is illustrated with some numeric examples that show reasonable behaviour of the model.
However, there are no theoretical results for model behaviour
(as we gave in Section~\ref{sec:gbicp-properties-criteria}),
and elicitation of the parameters ($\alpha,\beta,\mu,\lambda,c^*_0,\xi$)
for an informative prior
seems quite difficult and possibly involves elaborate pre-posterior procedures,
as the influence of different choices of $l(\theta)$ and $a(\theta)$ on $\mathcal{M}$
is rather oblique.%
\footnote{However, the elicitation method by \textcite{2011:rinderknecht} could be used
to elicit $\alpha,\ \beta,\ \mu,\ \lambda$, and $c^*_0$.}

\medskip

\textcite{2009:bickis} suggests a multivariate logit-normal model as an alternative to the IDM
for an application where neighbouring category probabilities $\theta_j$ are correlated.
Instead of the conjugate Dirichlet prior for $\btheta$ (see Section~\ref{sec:diri-multi}),
a multivariate normal prior is assumed for the (element-wise) logits of $\btheta$,
i.e., $\log(\btheta/(1-\btheta)) \sim \norm_k(\mu \mbf{1}, \sigma^2\mbf{R})$,
where $\mbf{1} = (1, \ldots, 1)$, and $\mbf{R}$ is a correlation structure.
The resulting posterior in terms of $\btheta$ is itself not tractable, but can be approximated
by an exponential family that can be seen as the convex hull of the logit-normal
and dirichlet families \parencite[p.~189]{2009:bickis},
and that contains the Dirichlet distribution for the limit $\sigma^2 \to \infty$.
Although a conjugate prior in the sense that there is a simple update step for the hyperparameters,
posterior inferences for this prior must usually be derived by simulation,
as there are, e.g., no results on the expectation of this distribution.
In the paper, a near-noninformative set of priors is constructed
by means of a set of hyperparameters,
used for an interesting application to estimate a discrete hazard function
for which it is useful to mirror an autocorrelation structure in $\mbf{R}$.
However, the potential of this prior model for applications where no correlation structure must be assumed is
relatively low, due to the much more complex computations as compared to the IDM.%
\footnote{For a recent Bayesian alternative to the IDM, see \textcite{2013:mangilibenavoli}, also mentioned in Section~***.}
It remains to be discovered how an informative (imprecise) prior could be elicited,
and the behaviour in case of \pdc\ is as yet unkown.



%Other work on exponential family sampling models includes \textcite{1993:coolen, 1994:coolen},
%who uses a different type of imprecise conjugate prior densities (interval of measures),
%and \textcite{2009:bickis}, who suggests the logit-normal model as an alternative to the IDM.


\subsection{Other Approaches Using Sets of Priors}
\label{sec:alternatives:other}

%comparison with other approaches based on sets of probability distributions


***then sets of priors in general: discrete models (comparison whitcomb),

***pericchi-walley???,

***mangili-benavoli???

***\textbf{neighbourhood models},

%interval of measures like 2011:rinderknecht ($l$ and $u$ non-conjugate?)
\textcite[\S 4]{2011:rinderknecht:diss} presents a model for inferences 
based on sets of priors of the form of a density-ratio class
bounded by parametric distributions
(see the elicitation method mentioned infootnote~\ref{foot:rinderknecht}, page~\pageref{foot:rinderknecht}).


Many other models have been investigated and applied, in particular neighborhood models
(see, e.g., the surveys \cite{2000:bergerinsuaruggeri} and \cite{2005:ruggeri}).
By studying credibility intervals, \textcite{1991:pericchi} give a neat overview on a number of approaches based on sets of priors,
%while \textcite{2011:rinderknecht} is an example of a study on elicitation for a certain class of priors that is both rigorous and accessible.

***discuss these approaches some more?***






\bigskip

***short discussion of work in BA Norbert Krautenbacher,
comparison to whitcomb, then rewrite this:

``Some computational aspects'' from \textcite[\S 4.2]{itip-statinf} on discrete models (Whitcomb!)***

In the case of discrete prior distributions (i.e., distributions with a finite support of size $k$)
%(where the unknown parameter can only assume a fixed number $k$ of values, $k < \infty$),
the computation of posterior credal sets is often done
via the alternative model formulation as conditional lower previsions
\parencite[see, e.g.,][]{itip-computation}.
For large $k$, the algorithms described there may easily become infeasible.
In traditional statistics, absolutely continuous distributions are employed
when inference using discrete distributions becomes too complex,
typically approximating a non-parametric model with a parametric one.%
\footnote{As an example, consider the test for independence in contingency tables.
Fisher's exact test, a non-parametric test using a permutation argument (thus resulting in a discrete distribution),
can become difficult to calculate for large samples.
An alternative is then the chi-squared test that is based on the continuous, one-parametric $\chi^2(df)$ distribution,
which, for large samples, is a good approximation of the distribution of the $\chi^2$ test statistic then used to determine the test decision.}
The same path can be followed in generalized Bayesian inference,
by considering sets of continuous distributions.
Furthermore, before the advent of Markov Chain Monte Carlo (MCMC) techniques \parencite[see, e.g.,][]{1998:gilks}
to determine posterior distributions in complex settings by simulation,
Bayesian inference was mostly confined to conjugate prior distributions
because posteriors derived from non-conjugate priors are very often intractable analytically.




\bigskip

***different sorts of neighbourhood models as considered in robust Bayesian approaches \parencite[e.g.,][]{1994:berger}.


As an example, consider the \emph{odds-ratio model}.
As a neighbourhood model,
it serves to model approximate adherence to a central probability law with distribution $\p_0$,
by giving the following constraints for pairs of events $A$ and $B$:
\begin{align*}
\frac{\p(A)}{\p(B)} \le (1-\epsilon)\frac{\p_0(A)}{\p_0(B)}\,,\quad A, B \subseteq \Omega
\end{align*}
The set of distributions $\p$ compatible with these restrictions
forms then an odds-ratio model with parameter $\epsilon$,
and can be represented by a lower prevision $\El_\epsilon$.
When such a model is taken as an imprecise prior in Bayesian inference,
the set of posteriors can again be expressed as an odds-ratio model
\parencite[\S 7.2]{itip-special}.
Other neighbourhood models, like, e.g., the $\epsilon$-contamination class
\parencite[see, e.g.,][\S 4.3.2]{1994:berger},
may instead not be closed under Bayesian updating.

In short, the theory of lower previsions or sets of probability distributions
provides a formal framework for robust Bayesian inference models
\parencite{1994:berger}.





\medskip

****par on what's next***





