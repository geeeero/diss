%\section{***Linear Regression Analysis under Sets of Conjugate Priors}
%\label{sec:isipta07}

%***short summary of ISIPTA'07 paper??***


\section{A Parameter Set Shape for Strong Prior-Data Agreement Modelling}
\label{sec:boatshape}

%march 2013 notes (technical results)
%Preliminary results
In this section, we will explain an approach for parameter set shapes
that allow for extra precision in case of strong prior-data agreement
as discussed in Section~\ref{sec:concluding-outlook}.
First, we will briefly characterise the novel parametrisation of canoncial conjugate priors this approach relies on.
To keep things simple, we restrict ourselves here for the case of the Beta-Binomial model
(see Section~\ref{sec:beta-binom}),
but the approach is generalisable to arbitrary canonical conjugate priors.%
\footnote{For a more detailed derivation of this parametrisation,
we have to refer to a future publication of Mi\c{k}elis Bickis.}
Then we will suggest a shape in this parametrisation that accomplishes
both \pdc\ sensitivity and `bonus precision' in case of strong prior-data agreement.
We present a parametric description for such a shape
and show that it will indeed lead to the desired properties.

\subsection{A Novel Parametrisation of Canonical Conjugate Priors}
\label{sec:miksworld}

In the parametrisation in terms of $\nz$ and $\yz$, described in Section~\ref{sec:regularconjugates},
a conjugate priors is updated to its respective posterior by a shift in the parameter space,
given by \eqref{eq:canonicalupdate}:
\begin{align*}
\nz &\mapsto \nz + n\,, &
\yz &\mapsto \frac{\nz}{\nz + n} \cdot \yz + \frac{n}{\nz + n} \cdot \frac{\tau(\x)}{n} = \yz + \frac{\tau(\x)-n\yz}{\nz+n}\,.
\end{align*}
We see thus that, while the shift for the $n$ coordinate is the same for all elements $(\nz,\yz)$
in a prior parameter set $\PZ$,
the shift in the $y$ coordinate depends on $\nz$, and the location of $\yz$ itself.
Due to this, the shape of $\PZ$ will change during the update step.

This shape change to some extent obscures the posterior inference properties
of a certain shape of the prior parameter set $\PZ$.
Therefore, a different parametrisation of the canonical priors
in which each coordinate has the same shift in updating would be advantageous.
Then, updating of parameter sets
could be expressed as a shift of the entire set within the parameter space.
%Although interpretation of the shapes may be slightly more difficult due to the,

A parametrisation developed by Mi\c{k}elis Bickis (\cite*{2011:bickis:geomip}, personal communication) achieves just that.
He is currently preparing a manuscript elaborating the details of his findings,
and we will present here a preview on the results for the Beta-Binomial case.

In this parametrisation, a canonical prior is represented by a coordinate $(\ezz,\eoz)$,%
\footnote{Again, we denote prior parameters with superscript ${}\uz$, and posterior parameters with superscript ${}\un$.}
where $\eoz$ replaces the main prior parameter $\yz$,
while $\ezz$ is just a different name for $\nz$.
The relation of $(\ezz,\eoz)$ to $(\nz, \yz)$ is as follows:
%\begin{equation}
\begin{align}
\label{eq:trafotony}
%\begin{aligned}
\nz &= \ezz \,, &
\yz &= \frac{\eoz}{\ezz + 2} + \frac{1}{2}\,.
%\end{aligned}
%\end{equation}
\end{align}

The domain of $\eta_0$ and $\eta_1$ in case of the Beta-Binomial model is
\begin{align}
\label{eq:eta-domain}
\Eta &= \Big\{ (\eta_0,\eta_1) \Big| \eta_0 > -2,\ |\eta_1| < \frac{1}{2}(\eta_0 + 2) \Big.\Big\}\,,
\end{align}
and the update step in terms of $\eta_0$ and $\eta_1$ is given by
\begin{equation}
\label{eq:eta-update}
\begin{aligned}
\eta_0\un &= \eta_0\uz + n\,, \\
\eta_1\un &= \eta_1\uz + \frac{1}{2}(s - (n-s)) = \eta_1\uz + s - \frac{n}{2}\,,
\end{aligned}
\end{equation}
where $s$ is the number of successes in the $n$ Bernoulli trials.
A `success' in a Bernoulli trial thus
leads to step of $1$ in the $\eta_0$ direction and of $+\frac{1}{2}$ in the $\eta_1$ direction,
while a `failure'
leads to step of $1$ in the $\eta_0$ direction and of $-\frac{1}{2}$ in the $\eta_1$ direction.%
\footnote{As in Section~\ref{sec:isipta11}, we  
will often treat $s$ as a a real-valued observation in $[0,n]$
because the continuous representation is convenient for our discussions,
keeping in mind that in reality it can only take integer values.}

\begin{figure}  %trim=l b r t
\centering
%\fbox{%
\includegraphics[trim = 80mm 45mm 80mm 60mm, clip, width=0.7\textwidth]{R/boatshape-domain}%
%}
\caption[Bounds for the domain of $\eta_0$ and $\eta_1$ for the Beta-Binomial model,
with rays of constant expectation for $y_c = \{0.1,0.2,\ldots,0.9\}$.]%
{Bounds for the domain of $\eta_0$ and $\eta_1$ for the Beta-Binomial model (black),
with rays of constant expectation for $y_c = \{0.1,0.2,\ldots,0.9\}$ (grey).}
\label{fig:boatshape-domain}
\end{figure}

As we wrote in Section~\ref{sec:concluding-outlook},
$\eta_1$ cannot have the convenient property of being equal to
the expectation of the mean sample statistic $\ttau(\x)$ (here, $s/n$),
as was the case for $y$.%
\footnote{For $\yz$, it holds that $\yz = \E\big[\E[\ttau(\x) \mid \psi] \mid \nz, \yz\big]$,
as mentioned in Section~\ref{sec:regularconjugates}.}
However, from \eqref{eq:trafotony} we can derive that coordinates $(\eta_0,\eta_1) \in \Eta$ satifying
\begin{align}
\label{eq:raysofconstantexpectation}
\eta_1 = f(\eta_0) &= (\eta_0 + 2)(y_c - \frac{1}{2}) 
\end{align}
will have a constant expectation $y_c$.
The domain $\Eta$, and these \emph{rays of constant expectation} emanating from the coordinate $(-2,0)$,
are depicted in Figure~\ref{fig:boatshape-domain}.


\subsection{Informal Rationale for Boat-Shaped Parameter Sets}
\label{boatshape-rationale}

When Mi\c{k}elis Bickis presented this parametrisation of conjugate priors at a talk \parencite{2011:bickis:geomip},
both Frank Coolen and the author of this thesis had independently the same basic idea
for a set shape that allows for both \pdc\ sensitivity
%and gives `bonus precision' if prior and data agree especially well,
and more precise inferences in case of strong prior-data agreement.
The basic idea for this shape is described informally below,
while a suggestion for a parametrisation of such a shape is described and discussed
in Section~\ref{sec:boatshape-2}.

In the parametrisation in terms of $(\nz,\yz)$ and $(\nn, \yn)$,
posterior inferences become more precise,
because the stretch in the main parameter dimension $y$, denoted by $\Delta_y(\PN)$,
tends to $0$ for $n \to \infty$ (see the discussion in Section~\ref{sec:gbicp-properties-criteria}).
In the domain $\Eta$ as depicted in Figure~\ref{fig:boatshape-domain},
instead the rays of constant expectation fan out for growing $n$, %**move outwards to the right,
while a parameter set will retain its size in updating.
Increased precision in a posterior parameter set $\EN$, which is just
its prior counterpart $\EZ$ shifted to the right,
is given by the fact the more $\EN$ is located to the right,
the fewer rays of constant expectation $\EN$ will intercept.
Imprecision in terms of $\E\big[\E[\ttau(\x) \mid \psi] \mid \nn, \yn\big] = \yn$
can thus be imagined as the size of the `shadow' that a set $\EN$ casts
when considering a light source in $(-2,0)$ (the point from which the rays of constant expectation emanate).
In short, the smaller this shadow, the more precise the inferences.

In the context of the model from Section~\ref{sec:miksworld},
we will denote by $\ynl$ and $\ynu$ the bounds of this shadow,
i.e.,
\begin{align*}
\ynl &:= \min_{(\ezn,\eon) \in \EN} \yn = \min_{(\ezn,\eon) \in \EN} \frac{\eon}{\ezn+2} + \frac{1}{2}\,, \\
\ynu &:= \max_{(\ezn,\eon) \in \EN} \yn = \max_{(\ezn,\eon) \in \EN} \frac{\eon}{\ezn+2} + \frac{1}{2}\,,
\end{align*}
and we call the coordinates $\argmin_{(\eta_0,\eta_1) \in \EN} \yn$ and $\argmax_{(\eta_0,\eta_1) \in \EN} \yn$
the \emph{touchpoints} of $\EN$ responsible for the shadow $[\ynl, \ynu]$.
Mutatis mutandis, the same definitions can be made for the prior set $\EZ$.

Due to the fanning out of rays, most shapes for $\EZ$ will lead to decreasing imprecision for increasing $n$.
Indeed, models of type~(\ref{enum:modeltypes-a}) from Section~\ref{sec:basicsetting},
where $\PZ = \nz \times [\yzl, \yzu]$,
are represented here again by a line segment $\EZ = \ezz \times [\eozl,\eozu]$,
such that the posterior touchpoints are, for any $s$ and $n$, $(\ezn,\eonl)$ and $(\ezz,\eonu)$,
where $\eonl$ and $\eonu$ are the updated versions of $\eozl$ and $\eozu$, respectively.
Due to \eqref{eq:eta-update}, it holds that $\eonu-\eonl = \eozu-\eozl$;
therefore, imprecision decreases here because a line segment of fixed size
will cast a smaller shadow when further to the right,
as illustrated in Figure~\ref{fig:boatshape-vertical}.

\begin{figure}  %trim=l b r t
\centering
%\fbox{%
\includegraphics[trim = 15mm 45mm 25mm 60mm, clip, width=\textwidth]{R/boatshape-vertical}%
%}
\caption[Line segment parameter set $\EZ$ %
and respective posterior sets for $s/n=0.5$ and $s/n=0.9$.]%
{Parameter set $\EZ = \ezz \times [\text{\underline{$\eta$}${}_1\uz$},\eozu]$ and respective posterior sets $\EN$
for $s/n=0.5$ (left) and $s/n=0.9$ (right). Note that all sets have the same size,
imprecision decreasing only through their position on the $\eta_0$ axis.}
\label{fig:boatshape-vertical}
\end{figure}

For \pdc\ sensitivity, we need shapes that cover a range of $\eta_0$ values,
for the same reasons as in the framework of Section~\ref{sec:basicsetting},
where only sets with a range of $\nz$ values offered this property.
Sets that are elongated along the rays of constant expectation
will behave here similar to the rectangular shapes of Section~\ref{sec:basicsetting}.
When shifted along its respective ray of constant expectation,
imprecision will be reduced as the shadow of the set will become smaller just as described above for line segments.
When such a shape is instead shifted away from its ray of constant expectation,
imprecision will be increased, as a prolonged shape that is now turned away from its ray 
will cast a larger shadow.%
\footnote{This will become clear from the depiction of boatshape sets in Figure~\ref{fig:boatshape-posterior-mik}.} 

A set $\EZ$ allowing for less imprecison in case of strong prior-data agreement
must also be able to cast a smaller shadow if the update shift goes into the direction of its ray,
%of $s/n$ according the information,
but we will enhance this effect by considering now also the properties
of the canonical posteriors the coordinates of $\EN$ represent.

We have seen that for the conjugate distributions themselves,
$\nz$ is generally a parameter determining the spread of the distribution
(e.g., in the Normal-Normal model (see Section~\ref{sec:norm-norm}), $\nz$ was the inverse variance),
such that we will have more precise inferences if the shadow bounds $\ynl$ and $\ynu$
are attained at higher values of $\eta_0$, leading to lower variances in the
`critical' distributions at the boundary of the posterior expectation interval $[\ynl,\ynu]$.
For this to happen, we need a shape for which the touchpoints responsible for $\ynl$ and $\ynu$
are attained at higher values of $\eta_0$ in case of strong prior-data agreement.
Shapes that accomplish this must have a curvature along their length in the direction
of the constant rays of expectation.
The shape we suggest thus looks like a bullett, or like a boat with a transom stern
(see, e.g., Figure~\ref{fig:boatshape-prior}).



\subsection{The Boatshape}
\label{sec:boatshape-2}

In this section, %~\ref{sec:boatshape-2} below,
%Now,
we will suggest a parametrisation for such a shape.
The definition, along with some first graphical examples, is given in Section~\ref{sec:basicdefboat},
and we discuss some first technical results for this shape in Sections~\ref{sec:touchpoints} -- \ref{sec:generalupdate}.

\subsubsection{Basic Definition}
\label{sec:basicdefboat}

We will now present a parametrisation for such a boat-shaped parameter set $\EZ$.
To keep things simple, we will consider here and in the follwing only prior sets
that are symmetric around the $\eta_0$ axis, i.e., centered around $y_c = 0.5$,
expressing prior the information that we deem a fraction of successes of $\frac{s}{n} = \frac{1}{2}$
as the most probable.%
\footnote{The general case of sets $\EZ$ with central ray $y_c \neq 0.5$
is discussed informally in Section~\ref{sec:boatshape-outlook}.}

For the contours of $\EZ$, we suggest an exponential function as the functional form,
where the `prow' of the set is located at $(\ezl, 0)$.
The lower and the upper contour $\czl(\eta_0)$ and $\czu(\eta_0)$ are defined as
\begin{align*}
\czl(\eta_0) &= -a \left( 1 - e^{-b(\eta_0 - \ezl)} \right)\,, \\
\czu(\eta_0) &= \phantom{-}%
                 a \left( 1 - e^{-b(\eta_0 - \ezl)} \right)\,, 
\end{align*}
where $a$ and $b$ are parameters controlling the shape.
We will also need the respective derivations with respect to $\eta_0$, given by
\begin{align*}
\frac{d}{d\eta_0} \czl(\eta_0) &= -ab e^{-b(\eta_0 - \ezl)}\,, \\
\frac{d}{d\eta_0} \czu(\eta_0) &= \phantom{-}%
                                   ab e^{-b(\eta_0 - \ezl)}\,.
\end{align*}

For this basic situation, given the parameters $\ezl$, $\ezu$, $a$, and $b$,
$\EZ$ is thus defined as
\begin{align}
\label{eq:basicset}
\EZ =
\{(\eta_0,\eta_1) \colon \ezl \le \eta_0 \le \ezu, \czl(\eta_0) \le  \eta_1 \le \czu(\eta_0) \}\,.
\end{align}
A prior boatshape set with $\ezl=1$, $\ezu=6$, $a=2$, and $b=0.8$ is depicted in Figure~\ref{fig:boatshape-prior},
where the left graph shows this set as defined in terms of $(\eta_0,\eta_1)$,
and the right graph shows the set from the left transformed into the space $\N \times \Y$.

\begin{figure}  %trim=l b r t
\centering
%\fbox{%
\includegraphics[trim = 15mm 45mm 25mm 60mm, clip, width=\textwidth]{R/boatshape-prior}%
%}
\caption[Boatshape prior set in the parametrisation via $(\eta_0,\eta_1)$ and via $(\nz,\yz)$.]%
{Boatshape prior set in the parametrisation via $(\eta_0,\eta_1)$ (left) and via $(\nz,\yz)$ (right),
with parameters $\ezl=1$, $\ezu=6$, $a=2$, and $b=0.8$.}
\label{fig:boatshape-prior}
\end{figure}


We have as yet no appealing formal description for the role of the parameters $a$ and $b$. %that,
%togeher with $\ezl$ and $\ezu$, define the boat-set (see Section~\ref{sec:basicdefboat} below).
Informally, $a$ determines the half-width of the set;
the width, i.e., the size in the $\eta_1$ dimension, would be $a$ if $\ezu \to \infty$.
$b$ instead determines the `bulkyness' of the shape.
Together with $\ezl$, $a$ and $b$ determine the prior interval for the expected success probability $[\yzl, \yzu]$.
For fixed $\ezl$ and $a$, increasing $b$ leads to a wider prior expectation interval.
For $[\yzl, \yzu]$, the choice of $\ezu$ is irrelevant.%
\footnote{$\ezu$ plays only a role in determining when the `unhappy learning' phase starts
(see end of Section~\ref{sec:generalupdate}).}


\begin{figure}  %trim=l b r t
\centering
%\fbox{%
\includegraphics[trim = 20mm 35mm 30mm 45mm, clip, width=\textwidth]{R/boatshape-posterior-mik}%
%}
\caption[Boatshape prior and posterior sets for data in accordance and in conflict with the prior.]%
{Boatshape prior and posterior sets for data in accordance and in conflict with the prior.
The prior set is the same as in Figure~\ref{fig:boatshape-prior}.
While the posterior sets for $\frac{s}{n}=0.5$ move along the ray for $y_c=0.5$,
the posterior sets for $\frac{s}{n}=1$ are shifted away from the ray for $y_c=0.5$,
resulting in increased posterior imprecision.
Note that lower and upper touchpoints are in the middle of the contour
for the prior and the posterior resulting for data $\frac{s}{n}=\frac{4}{8}$,
while at least one touchpoint is at the end for all other sets.
(see also Figure~\ref{fig:boatshape-posterior-normal}).}
\label{fig:boatshape-posterior-mik}
\end{figure}


\begin{figure}  %trim=l b r t
\centering
%\fbox{%
\includegraphics[trim = 15mm 45mm 25mm 60mm, clip, width=\textwidth]{R/boatshape-posterior-normal}%
%}
\caption[Boatshape prior and posterior sets from Figure~\ref{fig:boatshape-posterior-mik} in the parametrisation via $(\nz,\yz)$.]%
{Boatshape prior and posterior sets from Figure~\ref{fig:boatshape-posterior-mik} in the parametrisation via $(\nz,\yz)$.
Note that in the strong prior-data agreement case,
posteriors based on a rectangular set with the same prior main parameter imprecision
would be larger than the ones depicted here, illustrating the extra gain in precision.}
\label{fig:boatshape-posterior-normal}
\end{figure}


\subsubsection{Finding the Touchpoints for the Basic Set}
\label{sec:touchpoints}

In contrast to models discussed in Section~\ref{sec:generalmodel},
where $\yzl$ and $\yzu$ were at either ends of a set $\PZ$,
here, for a set \eqref{eq:basicset}, the touchpoints $\yzl$ and $\yzu$ 
are not necessarily at $\ezzl$ or $\ezzu$.
\footnote{See, e.g., the prior in Figure~\ref{fig:boatshape-prior}.}
Instead, the rays of constant expectation \eqref{eq:raysofconstantexpectation}
touching the parameter set must be determined to find $\yzl$ and $\yzu$.
To do this, the tangent equations for the lower and the upper contour function
depending on $\eta_0$ are determined.
As all rays of constant expectation pass through the point $(-2,0)$,
the tangent that passes through this point is determined by inserting this point
into the tangent equation, and the resulting equation is solved for $\eta_0$.
The resulting points $(\eta_0^u,\czu(\eta_0^u))$ resp.\ $(\eta_0^l,\czl(\eta_0^l))$
then give the touchpoints of the parameter set,
and can be transformed to $\yzl$ and $\yzu$ by using \eqref{eq:trafotony}.

As the basic set is symmetrical to the $\eta_0$ axis, $\eta_0^u = \eta_0^l$,
and it suffices to find, e.g., $\eta_0^u$, by considering the upper contour tangent.

We denote the tangent in contour point $(\eta_0,\czu(\eta_0))$ by
\begin{align*}
\ol{t}_{\eta_0}(x) &= dx + i\,,
\end{align*}
where $d = \frac{d}{d\eta_0} \czu(\eta_0)$ and
$i$ such that $\ol{t}_{\eta_0}(x)$ goes through the point $(\eta_0,\czu(\eta_0))$:
\begin{align*}
\ol{t}_{\eta_0}(x) &= dx + i \quad \equiv\\
\czu(\eta_0) &= \frac{d}{d\eta_0} \czu(\eta_0) \eta_0 + i \\
i &= \czu(\eta_0) -\frac{d}{d\eta_0} \czu(\eta_0) \eta_0 \\
  &= a - a e^{-b(\eta_0 - \ezl)} - \eta_0 ab e^{-b(\eta_0 - \ezl)} \\
  &= a - a (1 + b \eta_0) e^{-b(\eta_0 - \ezl)} \\
\Longrightarrow\quad
\ol{t}_{\eta_0}(x) &= ab e^{-b(\eta_0 - \ezl)} x + a - a (1 + b \eta_0) e^{-b(\eta_0 - \ezl)} \\
                   &= a - a \big(1 + b(\eta_0-x)\big) e^{-b(\eta_0 - \ezl)}
\end{align*}

Now, let us find the touchpoint $(\eta_0^u, \czu(\eta_0^u))$ whose tangent goes through $(-2,0)$, as this gives us $\yzu$.
We insert $(-2,0)$ into the tangent equation and solve for $\eta_0$.
\begin{align}
a - a \big(1 + b(\eta_0^u + 2)\big) e^{-b(\eta_0^u - \ezl)} &\stackrel{!}{=} 0 \nonumber\\
1 + b(\eta_0^u + 2) &\stackrel{!}{=} e^{b(\eta_0^u - \ezl)} \label{eq:eta0u}
\end{align}
This equation has only one solution for $\eta_0^u > \ezl$, that is,
however, not available in closed form.

As a general rule, the nearer $\eta_0^u$ is to $\ezl$, the larger $\frac{d}{d\eta_0} \czu(\eta_0^u)$,
that is, $\yzu$ %the upper expected value for the prior set
is more away from $\frac{1}{2}$.
Here, this means that the larger $\eta_0^u$, the more imprecise is the prior parameter set.


\subsubsection{Strong Prior-Data Agreement Property}
\label{sec:spda-property}

We will now prove the essential property that sets \eqref{eq:basicset}
will lead to especially precise inferences when data are strongly suporting prior information.

For a prior parameter set $\EZ = \ezz \times [\eozl,\eozu]$
%, with $\eta_0 = \ezz$ fixed and $\eta_1$ varying in an interval $[\eol, \eou]$
symmetric around $0$,
the prior upper expected value $\yzu$
results from the transformation \eqref{eq:trafotony} of the point $(\ezz,\eozu)$.
The posterior upper expected value $\ynu$,
given data that coincide especially well with the prior,
i.e., data with $s = \frac{n}{2}$, will then be found at the point $(\ezz+n,\eozu)$,
because in this case, the set does not move in the vertical ($\eta_1$) direction.
As $\yz$ is decreasing in $\eta_0$ and $\eta_1$ is constant, $\ynu$ %the posterior upper expected value
will be lower than $\yzu$, i.e., imprecision is reduced.

Imprecision is, however, even more strongly reduced for the boatshape parameter set \eqref{eq:basicset}.
Say, we define the prior parameter set such that the prior upper touchpoint
is at the $\eta_0$ coordinate $\eta_0^u = \ezz$.
For this shape, the $\eta_0$ coordinate for the posterior upper touchpoint ${\eta_0^u}\un$
will be  larger than the updated $\ezz$, i.e., ${\eta_0^u}\un > \ezz + n$ (as will be shown below), and thus $\ynu$ is lower.
Although the $\eta_1$ coordinate will be slightly larger at the point $({\eta_0^u}\un, \ol{c}({\eta_0^u}\un))$
as compared to the point $(\ezz+n,\eozu)$, the corresponding $\ynu$ is still lower,
as it holds that
\begin{align*}
\frac{d}{d\eta_0} \ol{c}({\eta_0^u}\un) < \frac{d}{d\eta_0} \ol{c}(\ezz + n)
\end{align*}
because $\frac{d}{d\eta_0} \ol{c}(\eta_0)$ is decreasing in $\eta_0$,
and a smaller slope for the tangent through $(-2,0)$ is equivalent to a lower $\ynu$.
This is the desired reduction in imprecision for the case of strong prior-data agreement,
also depicted exemplarily in Figures~\ref{fig:boatshape-posterior-mik} and \ref{fig:boatshape-posterior-normal}.

The property ${\eta_0^u}\un > \ezz + n$ of the boatshape set will be shown below.
Due to symmetry of prior and posterior parameter shape around the $\eta_0$ axis,
${\eta_0^u}\un = {\eta_0^l}\un$, i.e.,
the touchpoint at the upper contour (giving $\ynu$) is equal to
the touchpoint at the lower contour (giving $\ynl$),
and thus, the argument formulated in terms of ${\eta_0^u}\un$ holds also for ${\eta_0^l}\un$.

The upper exponential contour for the posterior boatshape,
updated with $s = \frac{n}{2}$, has its `prow' now at $(\ezl + n, 0)$,
and is defined by the function
\begin{align*}
\ol{c}(\eta_0) &= a \left( 1 - e^{-b(\eta_0 - n -\ezl)} \right) \\
\frac{d}{d\eta_0} \ol{c}(\eta_0) &= ab e^{-b(\eta_0 - n - \ezl)} \,.
\end{align*}

The tangent in contour point $(\eta_0,\ol{c}(\eta_0))$ is
\begin{align*}
\ol{t}_{\eta_0}(x) &= a - a \big(1 + b(\eta_0-x)\big) e^{-b(\eta_0 - n - \ezl)} \,.
\end{align*}

Again, we insert $(-2,0)$ into this tangent equation and solve for $\eta_0$.
\begin{align}
a - a \big(1 + b({\eta_0^u}\un + 2)\big) e^{-b({\eta_0^u}\un - n - \ezl)} &\stackrel{!}{=} 0 \nonumber\\
1 + b({\eta_0^u}\un + 2) &\stackrel{!}{=} e^{b({\eta_0^u}\un - n - \ezl)} \,.\label{eq:eta0uposterior}
\end{align}
We compare now \eqref{eq:eta0uposterior} to \eqref{eq:eta0u} and conclude
that indeed ${\eta_0^u}\un > \ezz + n$.

\begin{figure}
\centering
\begin{tikzpicture}[pin distance=1cm]
\node (0,0) {%\fbox{% %trim=l b r t
\includegraphics[trim = 45mm 35mm 45mm 45mm, clip, width=\textwidth]{R/prior-vs-posterior-eta0u}%
};
\coordinate (x1) at (-0.35,-1.21);
\draw (x1) circle (2.5pt);
\coordinate [pin=-93:${\eta_0^u}\uz$] (a1) at (-0.35,-3.24);
\draw[dashed] (x1) -- (a1);
\coordinate (x2) at ( 5.2 ,-0.15);
\draw (x2) circle (2.5pt);
\coordinate [pin=-75:${\eta_0^u}\un$] (a2) at ( 5.2,-3.24);
\draw[dashed] (x2) -- (a2);
\coordinate (x1n) at (3.8,-1.21);
%\draw (x1n) circle (2.5pt);
%\coordinate [label=below:${\eta_0^u}\uz + n$] (a1n) at (3.8,-3.5);
\coordinate [pin=-93:${\eta_0^u}\uz + n$] (a1n) at (3.8,-3.24);
\draw[dashed] (x1) -- (x1n) -- (a1n);
\end{tikzpicture}
\caption{Illustration for the argument that ${\eta_0^u}\un > {\eta_0^u}\uz + n$.}
\label{fig:spda1}
\end{figure}

In Figure~\ref{fig:spda1}, the two exponential graphs have the same curvature,
the right one is the same as the left, only being shifted to the right by $n$.
The value of $\ezz + n$, defined as the abscissa of the intersection of the left exponential and the linear function,
being shifted to the right by $n$, would thus be on the right exponential curve.
Because ${\eta_0^u}\un$ results from the intersection of the right exponential curve and the linear function,
it is necessarily larger than ${\eta_0^u}\uz + n$, as the linear function is increasing.


\subsubsection{General Update with \texorpdfstring{$s > \frac{n}{2}$}{s > n/2}}
\label{sec:generalupdate}

Let us now consider the update of the basic boatshape \eqref{eq:basicset} %symmetric around the $\eta_0$ axis,
in the general case $s \neq \frac{n}{2}$.
Due to symmetry of the prior set, we can, without loss of generality,
consider again only the case $s > \frac{n}{2}$.

For the prior set, being symmetric around the $\eta_0$ axis,
both touchpoints are located at the same $\eta_0$ coordinate,
the resulting $\yzl$ and $\yzu$ having the same distance to $0.5$.
Regarding the posterior set, according to \eqref{eq:eta-update},
$\eta_0$ coordinates are incremented by $n$, while
$\eta_1$ coordinates are incremented by $s+\frac{n}{2}$.
That is, if $s \neq \frac{n}{2}$, the updated set is no longer symmetric around the $\eta_0$ axis,
such that we must consider the lower and upper contours separately.

The upper and lower contours and their respective derivatives for the updated boatshape set are now
\begin{align*}
\ol{c}(\eta_0)                   &= s - \frac{n}{2} + a - a e^{-b(\eta_0 - n - \ezl)} \,,\\
\frac{d}{d\eta_0} \ol{c}(\eta_0) &=                      ab e^{-b(\eta_0 - n - \ezl)} \,,\\
\ul{c}(\eta_0)                   &= s - \frac{n}{2} - a + a e^{-b(\eta_0 - n - \ezl)} \,,\\
\frac{d}{d\eta_0} \ul{c}(\eta_0) &=                     -ab e^{-b(\eta_0 - n - \ezl)} \,.
\end{align*}
The upper and lower tangents in contour point $(\eta_0,c(\eta_0))$ are now given by
\begin{align*}
\ol{t}_{\eta_0}(x) &= s - \frac{n}{2} + a - a \big(1 + b(\eta_0-x)\big) e^{-b(\eta_0 - n - \ezl)} \,,\\
\ul{t}_{\eta_0}(x) &= s - \frac{n}{2} - a + a \big(1 + b(\eta_0-x)\big) e^{-b(\eta_0 - n - \ezl)} \,.
\end{align*}
Inserting again $(-2,0)$, we get the equations defining the $\eta_0$ coordinates
${\eta_0^u}\un$ and ${\eta_0^l}\un$
that give us $\ynu$ and $\ynl$, respectively:
\begin{align}
%s - \frac{n}{2} + a - a \big(1 + b(\eta_0^u + 2)\big) e^{-b(\eta_0^u - n - \ezl)} &\stackrel{!}{=} 0 \nonumber\\
\label{eq:eta0u-general}
\frac{a}{s - \frac{n}{2} + a} \big(1 + b(\eta_0^u + 2)\big) &\stackrel{!}{=} e^{b(\eta_0^u - n - \ezl)} \,,\\
\label{eq:eta0l-general}
\frac{a}{\frac{n}{2} -s  + a} \big(1 + b(\eta_0^u + 2)\big) &\stackrel{!}{=} e^{b(\eta_0^u - n - \ezl)} \,.
\end{align}

We see thus that the picture from Figure~\ref{fig:spda1} holds here as well,
except that the linear function (left hand side of equations
\eqref{eq:eta0u-general} and \eqref{eq:eta0l-general}) is changed in slope and intercept by a factor.
(Equivalently, we can consider it to be rotated around the root $-2-\frac{1}{b}$.)
For $s=\frac{n}{2}$, this factor is 1 for both the lower and the upper touchpoint,
resulting in the situation of strong prior-data agreement as considered in Section~\ref{sec:spda-property},
where ${\eta_0^u}\un = {\eta_0^l}\un$ moved to the right.

Due to symmetry, we will consider the case $s > \frac{n}{2}$ only 
to describe ${\eta_0^u}\un$ and ${\eta_0^l}\un$.

\paragraph{Description of ${\eta_0^u}\un$.}

The factor to the linear function $\frac{a}{s - \frac{n}{2} + a}$
in \eqref{eq:eta0u-general} is smaller than $1$ and decreasing in $s$.
Thus, the larger $s$, the smaller the factor, the most extreme case being $s=n$,
where the factor is $\frac{a}{\frac{n}{2} + a}$.
As the linear function's slope will be less steep (the intercept is lowered as well),
%\footnote{The common root of the linear functions for any $s$ is at $\eta_0 = -2 -\frac{1}{b}$.}
the intersection with the exponential function moves to the left,
i.e.\ $\eta_0^u(s) < \eta_0^u(\frac{n}{2})$ for $\frac{n}{2} < s \le n$.
This means that $\ynu(s) > \ynu(\frac{n}{2})$ in general.
However, decrease of $\eta_0^u(s)$ is limited by $\ezl+n$.
When the intersection point reaches the left end of the shape at $\ezl+n$,
the gradual increase of $\ynu$ through the changing tangent slope 
for $\ezl+n \le \eta_0^u(s) \le \eta_0^u(\frac{n}{2})$ is replaced
by a different change mechanism,
where increase of $\ynu$ is solely due to increase in the $\eta_1$ direction.
Due to \eqref{eq:trafotony}, $\ynu$ is then linear in $s$.

\paragraph{Description of ${\eta_0^l}\un$.}

In \eqref{eq:eta0l-general}, the factor to the linear function is $\frac{a}{\frac{n}{2} - s + a}$.
Here, we have to distinguish the two cases $\frac{n}{2} \le s < \frac{n}{2} + a$
and $s \ge \frac{n}{2} + a$.
In the first case, the factor is larger than $1$ and increasing in $s$.
Therefore, the intersection of the linear function with the exponential function
will move towards the right, i.e., we will have a larger ${\eta_0^l}\un$, and $\ynl$ increases.
In the second case, the factor is undefined (for $s = \frac{n}{2} + a$)
or negative (for $s > = \frac{n}{2} + a$).
Either way, there will be no intersection of the linear function with the exponential function
for any $\eta_0 > \ezl + n$ (For $s \to \frac{n}{2} + a$, the slope $\to \infty$).
In fact, for $s \ge \frac{n}{2} + a$, the whole shape is above the $\eta_0$ axis,
and the touchpoint must be thus at $\ezu + n $.
Actually, $\ezu + n$ will be the touchpoint already at some $\frac{n}{2} \le s < \frac{n}{2} + a$,
when the intersection point arrives at $\ezu + n$.
At this point, gradual increase of $\ynl$ resulting from the movement of ${\eta_0^l}\un$ along the set
towards the right is replaced by a linear increase in $s$.
Again, this linear increase is due to the $\eta_1$ coordinate being incremented
according to \eqref{eq:eta-update},
and from \eqref{eq:trafotony} we see that $\ynl$ is linear in $\eta_1$.

%Contrary to the former consideration, the posterior boatshape set updated with $s > \frac{n}{2}$
%is not symmetric around the $\eta_0$ axis.
%To compare the posterior imprecision for $s=\frac{n}{2}$ with $s > \frac{n}{2}$,
%we have to consider also $\ynl$ for both cases.

%$\ynl(\frac{n}{2})$, i.e.\ the posterior lower expectation for $s=\frac{n}{2}$,
%can be found, due to symmetry around the $\eta_0$ axis, at ${\eta_0^l}\un = {\eta_0^u}\un$. 

\paragraph{Synthesis.}

For $s > \frac{n}{2}$, both $\ynu$ and $\ynl$ will at first increase gradually with $s$,
as ${\eta_0^u}\un$ moves to the left, and ${\eta_0^l}\un$ moves to the right.
We will call such updating of the prior parameter set,
where neither posterior touchpoints are at the left or the right end of the set, as `happy learning'.

At some $s^u$, ${\eta_0^u}\un$ will arrive at $\ezl + n$,
and at some $s^l$, ${\eta_0^l}\un$ will arrive at $\ezu + n$.
Whether $s^l < s^u$ or the other way round depends on
the choice of parameters $\ezl, \ezu, a$ and $b$.
Either way, once $s$ is larger than either of $s^l$ or $s^u$,
we switch to ``unhappy learning'',
where data $s$ is very much out of line with our prior expectations as expressed
by the prior parameter set $\EZ$.
Ultimately, when $s > s^u$ and $s > s^l$,
both $\ynu$ and $\ynl$ will increase linearly in $s$, but with different slopes.
$\ynu$ will increase with slope $\frac{1}{\ezl + n + 2}$,
whereas $\ynl$ will increase with a lower slope $\frac{1}{\ezu + n + 2}$.


\subsection{Discussion and Outlook}
\label{sec:boatshape-outlook}

Taking advantage of a novel parametrisation derived by Mi\c{k}elis Bickis that was shortly sketched in Section~\ref{sec:miksworld},
we proposed a prior parameter set shape with the aim to model strong prior-data agreement.
Our preliminary studies show some very appealing results for the Beta-Binomial model.
Our conjectures about boat-shaped parameter sets in the parametrisation via $(\eta_0,\eta_1)$,
described in Section~\ref{boatshape-rationale},
could be confirmed in our preliminary studies subsumed in Section~\ref{sec:boatshape-2}.

In these studies, we confined ourselves to sets symmetric around the $\eta_0$ axis,
thus expressing prior information suggesting values of $\frac{s}{n}$ close to $\frac{1}{2}$.
As we mentioned in Section~\ref{boatshape-rationale},
prior sets symmetric around rays of constant expectation \eqref{eq:raysofconstantexpectation}
may express prior information with a stress on $\frac{s}{n}=y_c$;
these can be obtained by rotating the set \eqref{eq:basicset} such that
its symmetry axis is on the ray of constant expectation with $y_c$.
Then, basically everything should work the same as described above,
except that for $y_c$ near to $0$ or $1$, one would have to take care to respect
the bounds of the parameter space.
Informally, we can also think of this as rotating the whole parameter space (the wedge)
under the boat-set until its symmetry axis is alingned to $y_c$. 

So far, we have only vague intuitions for the role of the parameters $a$ and $b$ that,
together with $\ezl$ and $\ezu$, define the shape.
An idea to find elicitation rules is to investigate also here `pre-posterior' strategies,
by letting the analyst reason on hypothetical counts and what she would like to learn from them.

Related to this, the concrete behaviour during `happy learning' is difficult to pinpoint exactly,
as there are no closed form solutions for ${\eta_0^u}\un$ and ${\eta_0^l}\un$.
Also, the exact threshold for $s$ where we transfer from `happy learning' to `unhappy learning'
(where strong prior-data conflict indicated by a linear increase of $\ynu$ and $\ynl$) is not available in closed form.
We plan to study these aspects of the model by numeric examples,
drawing $\ynl$ and $\ynu$ against $s$ for some exemplary choices of $a, b, \ezl$ and $\ezu$,
similarly to the \emph{predictive probability plots} given in Section~\ref{sec:isipta11}.%
\footnote{Examples for these plots are Figures~\ref{fig:priorset-generic},
\ref{fig:anteater-nsmall}, and \ref{fig:weighted-generic}.}

Regarding more advanced considerations on elicitation, if the severity of deviations
in the upper ($\frac{s}{n} > y_c$) and in the lower ($\frac{s}{n} < y_c$) direction
differ for the analyst
(e.g., she wants to be less imprecise for $\frac{s}{n} < y_c$, although she still thinks $\frac{s}{n} \approx y_c$),
$a$ and $b$ could be different for the lower and the upper contour.
Furthermore, in this parametrisation, it is possible to elicit sets $\EZ$
that are near-noninformative with respect to $\yz$,
but nevertheless can express preferences towards a certain success fraction by being symmetric around $y_c$.
Such an approach could be similar to the priors suggested by \textcite{1996:atwood} and \textcite{2011:kelly:atwood}
mentioned in Section~\ref{sec:epistemic-alpha},
opening up interesting research questions regarding the relation of near-noniformativeness
to situations with substantial prior information.

%A joint publication of Mi\c{k}elis Bickis, Frank Coolen and the author of this thesis is planned
%in which we will elaborate the approach sketched here in more detail.





%
