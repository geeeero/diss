\chapter{Introduction}


\begin{itemize}
\item overview, which paper used where\ldots
\item statistical inference ??? (\textbf{StatInf chapter}, \cite{itip-statinf})
\item Bayesian inference, conjugate priors, etc. (\textbf{TechRep Dirichlet}, \cite{Walter2012b})
\item motivate priors etc.\ with ress paper: \cite{Walter2013a}
\item short part on decision theory, updating rules?
\item \pdc\ (Evans \& Moshonov), examples (\textbf{Festschrift paper}, \cite{Walter2010a})
\item other motivations for IP?
\end{itemize}

\section{Overview}

***structure, which papers where***

Sec.~\ref{sec:stat-inference}: parts of \cite{itip-statinf}

Sec.~\ref{sec:bayes-inference}: parts of \cite{itip-statinf}

\section{Statistical Inference}
\label{sec:stat-inference}

%This thesis being concerned with generalized Bayesian Inference

In this Section, we will give a short introduction to statistical inference
and models that are used to describe random samples.
%These introductory sections may also serve as a guide to the notation utilized.

Statistical inference is about learning from data.
It is basically concerned with inductive reasoning,
i.e.\ establishing a general rule from observations.
As is long known as the problem of induction \cite{1739:hume},
it is impossible to justify inductive reasoning by pure reason,
and therefore one cannot infer general statements (laws) with absolute truth from single observations.
%***statistical models are built for a certain purpose. (citexxx George P. Box, Kaplan?)\\
%***models try to mirror certain aspects of reality: those deemed relevant to answer %the question(s) at hand etc.
The statistical remedy for this inevitable and fundamental dilemma of any type of inductive reasoning is
(postulated, maybe virtual) \emph{randomness} of the sampling process that generates the data.
If, and only if, the sample is, or can be understood as, drawn randomly,
probability theory allows to quantify the error of statistical propositions concluded from the sample.

Specifically, to model the randomness, a \emph{statistical model} is formulated.
It is a tuple $(\mathcal{X}, \mathcal{Q})$, consisting of the \emph{sample space} $\mathcal{X}$,
i.e.\ the domain of the random quantity $X$ under consideration,
and a set $\mathcal{Q}$ of probability distributions,%
\footnote{Most models of statistical inference rely on $\sigma$-additive probability distributions.
Therefore, technically, in addition an appropriate ($\sigma$-)field $\sigma(\mathcal{X})$,
describing the domain of the underlying probability measure, has to be specified.
In most applications there are straightforward canonical choices for $\sigma(\mathcal{X})$,
and thus $\sigma$-fields are not explicitly discussed here.}
collecting all probability distributions that are judged to be potential candidates for the distribution of $X$.
In this setting $\mathcal{Q}$ is called \emph{sampling model} and every element $p\in \mathcal{Q}$ \emph{(potential) sampling distribution}.
The inferential task is to learn the true element $p^* \in \mathcal{Q}$ from multiple observations of the random process producing $X$.


\subsection{Parametric Models}

In this thesis, generally, so-called \emph{parameteric models} are considered,
where $\mathcal{Q}$ is pa\-ra\-me\-trized by a parameter $\vartheta$ of finite dimension,
assuming values in the so-called \emph{parameter space} $\Theta$, $\Theta \subseteq \reals^q, \ q < \infty$,
i.e.\ ${\cal Q}=\left(p_\vartheta\right)_{\vartheta \in \Theta}$.
Here, the different sampling distributions $p_\vartheta$ are implicitly understood as belonging to a specific class of distributions
(e.g. normal distributions, see the example in ****),
the basic type of which is assumed to be known completely,
and only some characteristics $\vartheta$ (e.g.\ the mean) of the distributions are unknown.

Throughout, we will assume (as is the case for all common applications)
that the underlying candidate distributions $p_\vartheta$ of the random quantity $X$
are either discrete or absolutely continuous with respect to the Lebesgue measure
(see, e.g. \cite[pp.~32f, 38]{1993:karr} for some technical details) for every $\vartheta \in \Theta$.
Then it is convenient to express every $p_\vartheta$ in the discrete case by its \emph{mass function} $f_\vartheta$,
with $f_\vartheta(x):=p_\vartheta(X=x),\forall x \in \mathcal{X}$,
and in the continuous case by its \emph{probability density function} (pdf) $f_\vartheta$,
where $f_\vartheta$ is such that $p_\vartheta(X \in [a,b]) = \int_a^b f_\vartheta(x) \dd x$.

An \emph{i.i.d.\ sample of size} $n$ (where \emph{i.i.d.}\ abbreviates independent, identically distributed)
\emph{based on the parametric statistical model} %
$(\mathcal{X}, (p_\vartheta)_{\vartheta \in \Theta})$ is a vector
\[
{\X}=(X_1, \ldots, X_n)^T %\label{120722-1}
\]
of independent random quantities $X_i$ with the same distribution $p_\vartheta$.
Then $\X$ is defined on $\mathcal{X}^n$ with probability distribution $p_\vartheta^{\otimes n}$
as the $n$-dimensional product measure describing the independent observations.
For Bayesian approaches as discussed here,
independence is often replaced by exchangeability (see, e.g., \cite[\S 4.2]{2000:bernardosmith}).
$p_\vartheta^{\otimes n}$ thus has the probability mass or density function
\[
\prod_{i=1}^{n} f_\vartheta(x_i) =: f_\vartheta(x_1, \ldots, x_n).%\label{120710-2}
\]
The term \emph{sample} is then also used for the concretely observed value(s) $\x=(x_1, \ldots, x_n)^T$.%
\footnote{Throughout, random quantities are denoted by capital letters, their values, or realizations, by small letters.}

Next, we will present two examples for basic parametric models that will be repeatedly discussed further on.


\subsection{The Normal Distribution}
\label{sec:normaldist}

A common model for observations that in principle can assume any value on the real line
is the \emph{normal distribution} with parameters $\mu$ and $\sigma^2$, also called the \emph{Gaussian distribution}.
Typical examples for data of this kind are scores in intelligence testing, or technical measurements in general.%
\footnote{The normal distribution is distinguished by the central limit theorem
(see, e.g., \cite[\S 7.3]{1993:karr}, or \cite[\S 9]{1968:breiman}), stating that, under regularity conditions,
the distribution of an appropriately scaled sum of $n$ standardized random variables converges to a normal distribution
for $n \longrightarrow \infty$.}

For each observation $x_i$, $i=1,\ldots, n$, the normal probability density is
\begin{align*}
f_{(\mu, \sigma^2)}(x_{i}) &= \frac{1}{\sqrt{2\pi\sigma^2}}\exp\Big\{ -\frac{1}{2\sigma^2}(x_{i} - \mu)^2 \Big\}\,,
\end{align*}
with the two parameters $\mu \in \reals$ and $\sigma^2 \in \reals_{>0}$
being in fact the mean and the variance of (the distribution of) $x_i$, respectively.
As a shortcut, we write $x_i \sim \norm(\mu, \sigma^2)$.
%a normal density with $\mu=0$ and $\sigma^2=1$ is displayed
%in Figure~\ref{inference:fig:normal-vs-cauchy}, page~\pageref{inference:fig:normal-vs-cauchy}.

With the independence assumption, the density of $\mbf{x} = (x_1,\ldots,x_n)$ amounts to
\begin{align}\label{eq:normaldens}
f_{(\mu, \sigma^2)}(\mbf{x})
 &= \prod_{i=1}^n f_{(\mu, \sigma^2)}(x_{i})
  = (2\pi\sigma^2)^{-\frac{n}{2}}\exp\Big\{ -\frac{1}{2\sigma^2}\sum_{i=1}^n (x_{i} - \mu)^2 \Big\}\,.
\end{align}

Later on, we restrict considerations to the case where the variance $\sigma_0^2$ is known, denoted by $x_i \sim \norm(\mu, \sigma_0^2)$.
Inference may thus concern the parameter $\mu$ directly, or future observations $x_{n+1}, x_{n+2}, \ldots$ in a chain of i.i.d.\ observations.


\subsection{The Multinomial Distribution}
\label{sec:multinomdist}

The \emph{multinomial distribution} is a common model for samples where only a limited number of distinct values can be observed.
%like in the data from an election poll, or from a pharmacological study asking about a certain set of adverse reactions.
These distinct values are often named \emph{categories} (hence the term \emph{categorical data}),
and are usually numbered from $1$ to $k$, without imposing any natural ordering on these values.
We have therefore a discrete distribution,
giving the probability for observing certain category counts $(n_1, \ldots, n_k) = \mbf{n}$ in a sample of $n$ observations in total.
Thus, $\sum_{j=1}^k n_j = n$.

We start the definition of the multinomial distribution by decomposing the collection of $n$ observations into its constituents,
single observations of either of the categories $1,\ldots,k$.
Such a single observation, often named \emph{multivariate Bernoulli observation}, can be encoded as a vector $x_i$ of length $k$,
where the $j$-th element, $x_{ij}$, equals $1$ if category $j$ has been observed, and all other elements being $0$.
Given the vectorial parameter $\theta$ of length $k$,
where the component $\theta_j$ models the probability of observing category $j$ in a single draw
(therefore $\sum_{j=1}^k \theta_j = 1$),
the probability for observing $x_i$ can be written as
\begin{align*}
f_\theta(x_i) = \prod_{j=1}^k \theta_j^{x_{ij}}\,.
\end{align*}
Assuming independence, the probability for observing a certain sequence $\mbf{x}$ of $n$ observations can thus be written as
\begin{align*}
f_\theta(\mbf{x}) &= \prod_{i=1}^n f_\theta(x_i)
             \propto \prod_{i=1}^n \prod_{j=1}^k \theta_j^{x_{ij}}
                   = \prod_{j=1}^k \theta_j^{\sum_{i=1}^n x_{ij}}
                   = \prod_{j=1}^k \theta_j^{n_j}\,,
\end{align*}
where $n_j = \sum_{i=1}^n x_{ij}$ tells us how often category $j$ was observed in the sample.

For the probability to observe a certain category count $(n_1, \ldots, n_k) = \mbf{n}$,
we have to account for the different possible orderings in $\mbf{x}$ leading to the same count vector $\mbf{n}$.
Therefore,
\begin{align}\label{eq:multinomdens}
f_\theta(\mbf{n}) &= \binom{n}{n_1,\ldots,n_k} \prod_{j=1}^k \theta_j^{n_j}
                   = \frac{n!}{n_1!\cdot \ldots \cdot n_k!} \prod_{j=1}^k \theta_j^{n_j}\,.
%             \propto \prod_{j=1}^k \theta_j^{n_j}\,.
\end{align}
As a shortcut, we write $\mbf{n} \sim \mult(\theta)$.


\section{Statistical Inference with the Bayesian Paradigm}
\label{sec:bayes-inference}

As the inference models discussed in this thesis are all based on the Bayesian approach to statistical inference,
we will now give a short introduction to the basic principles of Bayesian inference.

The Bayesian approach allows (possibly subjective) knowledge on the parameter $\vartheta$ to be expressed by a probability distribution on%
\footnote{Again we implicitly assume that $\Theta$ is complemented by an appropriate $\sigma$-field $\sigma(\Theta)$.}
$\Theta$, with probability mass or density function $p(\vartheta)$ called \emph{prior distribution}.
Interpreting the elements $f_\vartheta(x)$ of the sampling model as conditional distributions of the sample given the parameter,
denoted by $f(\mbf{x}\mid\vartheta)$ and called \emph{likelihood},
turns the problem of statistical inference into a problem of probabilistic deduction,
where the \emph{posterior distribution}, i.e.\ the distribution of the parameter given the sample data,
can be calculated by Bayes' Rule.%
\footnote{Donald Gillies \cite{1987:gillies, 2000:gillies} argues that Bayes' Theorem was actually developed
in order to confront the problem of induction as posed by Hume \cite{1739:hume}.}
Thus, in the light of the sample $\mbf{x}= (x_1, \ldots, x_n)$ the prior distribution is updated by Bayes' Rule
to obtain the posterior distribution with density or mass function
\begin{align}
\label{eq:bayesrule}
p(\vartheta\mid\mbf{x}) \propto f(\mbf{x}\mid\vartheta) \cdot p(\vartheta)\,.
\end{align}
The posterior distribution is understood as comprising all the information from the sample and the prior knowledge.
It therefore underlies all further inferences on the parameter $\vartheta$,
like point estimators, interval estimators,
or the \emph{posterior predictive distribution},
which is the distribution of further observations based on $p(\vartheta\mid\mbf{x})$
(see Eq.~\eqref{eq:posteriorpredictive} below).


\subsection{Regular Conjugate Families of Distributions}

Traditional Bayesian inference is frequently based on so-called \emph{conjugate priors} related to a specific likelihood.
Such priors have the convenient property that the posterior resulting from~\eqref{eq:bayesrule}
belongs to the same class of parametric distributions as the prior, and thus only the parameters have to be updated,
which makes calculation of the posterior and thus the whole Bayesian inference easily tractable.

Fortunately, there are general results guiding the construction of conjugate priors in models used most frequently in practice,
namely in the case where the sample distribution belongs to a so-called \emph{(regular) canonical exponential family}
\cite[pp.~202 and 272f]{2000:bernardosmith}. %Def.~4.12 and Prop.~5.6
This indeed covers many sample distributions relevant in a statistician's everyday life,
like Normal and Multinomial models, Poisson models, or Exponential and Gamma models.
After presentation of the general framework, we will discuss its instantiation for the Normal
and the Multinomial sampling models as introduced in Sections~\ref{sec:normaldist} and \ref{sec:multinomdist} above.

A sample distribution
(from now on understood directly as the distribution $p_\vartheta^{\otimes n}$ of an i.i.d.\ sample $\mbf{x}$ of size $n$)
is said to belong to the \emph{(regular) canonical exponential family} if its density or mass function satisfies the decomposition
\begin{align}\label{eq:expofam-sampledens}
f(\x \mid \theta) &\propto \exp\big\{\langle \psi, \tau(\x) \rangle - n \mbf{b}(\psi)\big\}\,,
\end{align}
where $\psi \in \Psi \subset \reals^q$ is a transformation of the (possibly vectorial) parameter $\theta \in \Theta$,
and $\mbf{b}(\psi)$ a scalar function of $\psi$ (or, in turn, of $\theta$).
$\tau(\x)$ is a function of the sample $\x$ that fulfills $\tau(\x) = \sum_{i=1}^n \tau^*(x_i)$,
with $\tau^*(x_i) \in \mathcal{T} \subset \reals^q$,
while $\langle\cdot, \cdot\rangle$ denotes the scalar product.
From these ingredients, a conjugate prior on $\psi$ can be constructed as%
\footnote{In our notation, ${}\uz$ denotes prior parameters; ${}\un$ posterior parameters.}
\begin{align}\label{eq:canonicalprior}
p(\psi \mid \nz, \yz) \dd\psi
 &\propto \exp\Big\{ \nz \Big[ \langle \yz, \psi \rangle - \mbf{b}(\psi) \Big] \Big\} \dd\psi\,,
\end{align}
where $\nz$ and $\yz$ are now the parameters by which a certain prior can be specified.
The domain of $\yz$ is $\Y$, the interior of the convex hull of $\mathcal{T}$;
$\nz$ must take strictly positive values for the prior to be proper (integrable to $1$).

An interpretation for these parameters will be given shortly.
First, let us calculate the posterior density for $\psi$.
The prior parameters $\yz$ and $\nz$ are updated to their posterior values $\yn$ and $\nn$ in the following way:
\begin{align}\label{eq:canonicalupdate}
\yn &= \frac{\nz}{\nz + n} \cdot \yz + \frac{n}{\nz + n} \cdot \frac{\tau(\x)}{n}\,, &
\nn &= \nz + n\,,
\end{align}
such that the posterior can be written as
\begin{align}\label{eq:canonicalposterior}
p(\psi \mid \x, \nz, \yz)
 =: p(\psi \mid \nn, \yn)
 &\propto \exp\Big\{ \nn \Big[ \langle \yn, \psi \rangle - \mbf{b}(\psi) \Big] \Big\} \dd\psi\,.
\end{align}
In this setting, $\yz$ and $\yn$ can be seen as the parameter describing the main characteristics of the prior and the posterior,
and thus we will call them \emph{main prior} and \emph{main posterior parameter}, respectively.
$\yz$ can also be understood as a prior guess for the random quantity $\ttau(\x) := \tau(\x)/n$ summarizing the sample,
as $\E[\ttau(\x) \mid \psi] = \nabla\mbf{b}(\psi)$,
where in turn $\E[\nabla\mbf{b}(\psi) \mid \nz, \yz] = \yz$ \cite{2000:bernardosmith}***more concrete***.

Characteristically, $\yn$ is a weighted average of this prior guess $\yz$ and the sample `mean' $\ttau(\x)$,
with weights $\nz$ and $n$, respectively.%
\footnote{This weighted average property of Bayesian updating with conjugate priors is an important issue
we comment on ***later / in Section~\ref{}***.}
Therefore, $\nz$ can be seen as ``prior strength'' or ``pseudocounts'',
reflecting the weight one gives to the prior as compared to the sample size $n$.
To make this more explicit, $\nz$ can be interpreted as the size of an imaginary sample
that corresponds to the trust on the prior information in the same way
as the sample size of a real sample
corresponds to the trust in conclusions based on such a real sample \cite[p.~258]{Walter2009a}.

The posterior $p(\psi \mid \nn, \yn)$ can be transformed back to a distribution on $\theta$
in order to deal with a commonly known parameter or distribution family for it
(as we will do in Section~\ref{}*** below.)
Besides the posterior itself, also the posterior predictive distribution
\begin{align}
\label{eq:posteriorpredictive}
f(\x^*\mid\x) &= \int f(\x^* \mid \psi) p(\psi \mid \nn, \yn) \dd\psi\,,
\end{align}
a distribution on future samples $\x^*$ after having seen a sample $\x$,
forms the basis for the different inference tasks. %as listed in Section~\ref{inference:sec:basictasks}.

The concretion of this framework for Bayesian inference with regular conjugate priors
is now demonstrated for the sampling models presented in Sections~\ref{sec:normaldist} and \ref{sec:multinomdist}.
The framework for the Multinomial model (Section~\ref{sec:multinomdist})
is then used for inferences in common-cause modeling,
which will serve as a real-world example illustrating the powers and shortcomings of standard Bayesian inference.

