\chapter{Introduction}


\begin{itemize}
\item overview, which paper used where\ldots
\item statistical inference ??? (\textbf{StatInf chapter}, \cite{itip-statinf})
\item Bayesian inference, conjugate priors, etc. (\textbf{TechRep Dirichlet}, \cite{Walter2012b})
\item motivate priors etc.\ with ress paper: \cite{Walter2013a}
\item short part on decision theory, updating rules?
\item \pdc\ (Evans \& Moshonov), examples (\textbf{Festschrift paper}, \cite{Walter2010a})
\item other motivations for IP?
\end{itemize}

\section{Overview}

***structure, which papers where***

Sec.~\ref{sec:stat-inference}: parts of \cite{itip-statinf}

Sec.~\ref{sec:bayes-inference}: parts of \cite{itip-statinf}

Sec.~\ref{sec:inferencetasks}: parts of \cite{itip-statinf}

Sec.~\ref{sec:beta-binom}: parts of \cite{itip-statinf}

\section{Statistical Inference}
\label{sec:stat-inference}

%This thesis being concerned with generalized Bayesian Inference

In this Section, we will give a short introduction to statistical inference
and models that are used to describe random samples.
%These introductory sections may also serve as a guide to the notation utilized.

Statistical inference is about learning from data.
It is basically concerned with inductive reasoning,
i.e.\ establishing a general rule from observations.
As is long known as the problem of induction \cite{1739:hume},
it is impossible to justify inductive reasoning by pure reason,
and therefore one cannot infer general statements (laws) with absolute truth from single observations.
%***statistical models are built for a certain purpose. (citexxx George P. Box, Kaplan?)\\
%***models try to mirror certain aspects of reality: those deemed relevant to answer %the question(s) at hand etc.
The statistical remedy for this inevitable and fundamental dilemma of any type of inductive reasoning is
(postulated, maybe virtual) \emph{randomness} of the sampling process that generates the data.
If, and only if, the sample is, or can be understood as, drawn randomly,
probability theory allows to quantify the error of statistical propositions concluded from the sample.

Specifically, to model the randomness, a \emph{statistical model} is formulated.
It is a tuple $(\mathcal{X}, \mathcal{Q})$, consisting of the \emph{sample space} $\mathcal{X}$,
i.e.\ the domain of the random quantity $X$ under consideration,
and a set $\mathcal{Q}$ of probability distributions,%
\footnote{Most models of statistical inference rely on $\sigma$-additive probability distributions.
Therefore, technically, in addition an appropriate ($\sigma$-)field $\sigma(\mathcal{X})$,
describing the domain of the underlying probability measure, has to be specified.
In most applications there are straightforward canonical choices for $\sigma(\mathcal{X})$,
and thus $\sigma$-fields are not explicitly discussed here.}
collecting all probability distributions that are judged to be potential candidates for the distribution of $X$.
In this setting $\mathcal{Q}$ is called \emph{sampling model} and every element $p\in \mathcal{Q}$ \emph{(potential) sampling distribution}.
The inferential task is to learn the true element $p^* \in \mathcal{Q}$ from multiple observations of the random process producing $X$.


\subsection{Parametric Models}
\label{sec:parametricmodels}

In this thesis, generally, so-called \emph{parameteric models} are considered,
where $\mathcal{Q}$ is pa\-ra\-me\-trized by a parameter $\vartheta$ of finite dimension,
assuming values in the so-called \emph{parameter space} $\Theta$, $\Theta \subseteq \reals^q, \ q < \infty$,
i.e.\ ${\cal Q}=\left(p_\vartheta\right)_{\vartheta \in \Theta}$.
Here, the different sampling distributions $p_\vartheta$ are implicitly understood as belonging to a specific class of distributions
(e.g. normal distributions, see the example in ****),
the basic type of which is assumed to be known completely,
and only some characteristics $\vartheta$ (e.g.\ the mean) of the distributions are unknown.

Throughout, we will assume (as is the case for all common applications)
that the underlying candidate distributions $p_\vartheta$ of the random quantity $X$
are either discrete or absolutely continuous with respect to the Lebesgue measure
(see, e.g. \cite[pp.~32f, 38]{1993:karr} for some technical details) for every $\vartheta \in \Theta$.
Then it is convenient to express every $p_\vartheta$ in the discrete case by its \emph{mass function} $f_\vartheta$,
with $f_\vartheta(x):=p_\vartheta(X=x),\forall x \in \mathcal{X}$,
and in the continuous case by its \emph{probability density function} (pdf) $f_\vartheta$,
where $f_\vartheta$ is such that $p_\vartheta(X \in [a,b]) = \int_a^b f_\vartheta(x) \dd x$.

An \emph{i.i.d.\ sample of size} $n$ (where \emph{i.i.d.}\ abbreviates independent, identically distributed)
\emph{based on the parametric statistical model} %
$(\mathcal{X}, (p_\vartheta)_{\vartheta \in \Theta})$ is a vector
\[
{\X}=(X_1, \ldots, X_n)^T %\label{120722-1}
\]
of independent random quantities $X_i$ with the same distribution $p_\vartheta$.
Then $\X$ is defined on $\mathcal{X}^n$ with probability distribution $p_\vartheta^{\otimes n}$
as the $n$-dimensional product measure describing the independent observations.
For Bayesian approaches as discussed here,
independence is often replaced by exchangeability (see, e.g., \cite[\S 4.2]{2000:bernardosmith}).
$p_\vartheta^{\otimes n}$ thus has the probability mass or density function
\[
\prod_{i=1}^{n} f_\vartheta(x_i) =: f_\vartheta(x_1, \ldots, x_n).%\label{120710-2}
\]
The term \emph{sample} is then also used for the concretely observed value(s) $\x=(x_1, \ldots, x_n)^T$.%
\footnote{Throughout, random quantities are denoted by capital letters, their values, or realizations, by small letters.}

Next, we will present two examples for basic parametric models that will be repeatedly discussed further on.


\subsection{The Normal Distribution}
\label{sec:normaldist}

A common model for observations that in principle can assume any value on the real line
is the \emph{normal distribution} with parameters $\mu$ and $\sigma^2$, also called the \emph{Gaussian distribution}.
Typical examples for data of this kind are scores in intelligence testing, or technical measurements in general.%
\footnote{The normal distribution is distinguished by the central limit theorem
(see, e.g., \cite[\S 7.3]{1993:karr}, or \cite[\S 9]{1968:breiman}), stating that, under regularity conditions,
the distribution of an appropriately scaled sum of $n$ standardized random variables converges to a normal distribution
for $n \longrightarrow \infty$.}

For each observation $x_i$, $i=1,\ldots, n$, the normal probability density is
\begin{align*}
f_{(\mu, \sigma^2)}(x_{i}) &= \frac{1}{\sqrt{2\pi\sigma^2}}\exp\Big\{ -\frac{1}{2\sigma^2}(x_{i} - \mu)^2 \Big\}\,,
\end{align*}
with the two parameters $\mu \in \reals$ and $\sigma^2 \in \reals_{>0}$
being in fact the mean and the variance of (the distribution of) $x_i$, respectively.
As a shortcut, we write $x_i \sim \norm(\mu, \sigma^2)$.
%a normal density with $\mu=0$ and $\sigma^2=1$ is displayed
%in Figure~\ref{inference:fig:normal-vs-cauchy}, page~\pageref{inference:fig:normal-vs-cauchy}.

With the independence assumption, the density of $\mbf{x} = (x_1,\ldots,x_n)$ amounts to
\begin{align}\label{eq:normaldens}
f_{(\mu, \sigma^2)}(\mbf{x})
 &= \prod_{i=1}^n f_{(\mu, \sigma^2)}(x_{i})
  = (2\pi\sigma^2)^{-\frac{n}{2}}\exp\Big\{ -\frac{1}{2\sigma^2}\sum_{i=1}^n (x_{i} - \mu)^2 \Big\}\,.
\end{align}

Later on, we restrict considerations to the case where the variance $\sigma_0^2$ is known, denoted by $x_i \sim \norm(\mu, \sigma_0^2)$.
Inference may thus concern the parameter $\mu$ directly, or future observations $x_{n+1}, x_{n+2}, \ldots$ in a chain of i.i.d.\ observations.


\subsection{The Multinomial Distribution}
\label{sec:multinomdist}

The \emph{multinomial distribution} is a common model for samples where only a limited number of distinct values can be observed.
%like in the data from an election poll, or from a pharmacological study asking about a certain set of adverse reactions.
These distinct values are often named \emph{categories} (hence the term \emph{categorical data}),
and are usually numbered from $1$ to $k$, without imposing any natural ordering on these values.
We have therefore a discrete distribution,
giving the probability for observing certain category counts $(n_1, \ldots, n_k) = \mbf{n}$ in a sample of $n$ observations in total.
Thus, $\sum_{j=1}^k n_j = n$.

We start the definition of the multinomial distribution by decomposing the collection of $n$ observations into its constituents,
single observations of either of the categories $1,\ldots,k$.
Such a single observation, often named \emph{multivariate Bernoulli observation}, can be encoded as a vector $x_i$ of length $k$,
where the $j$-th element, $x_{ij}$, equals $1$ if category $j$ has been observed, and all other elements being $0$.
Given the vectorial parameter $\theta$ of length $k$,
where the component $\theta_j$ models the probability of observing category $j$ in a single draw
(therefore $\sum_{j=1}^k \theta_j = 1$),
the probability for observing $x_i$ can be written as
\begin{align*}
f_\theta(x_i) = \prod_{j=1}^k \theta_j^{x_{ij}}\,.
\end{align*}
Assuming independence, the probability for observing a certain sequence $\mbf{x}$ of $n$ observations can thus be written as
\begin{align*}
f_\theta(\mbf{x}) &= \prod_{i=1}^n f_\theta(x_i)
             \propto \prod_{i=1}^n \prod_{j=1}^k \theta_j^{x_{ij}}
                   = \prod_{j=1}^k \theta_j^{\sum_{i=1}^n x_{ij}}
                   = \prod_{j=1}^k \theta_j^{n_j}\,,
\end{align*}
where $n_j = \sum_{i=1}^n x_{ij}$ tells us how often category $j$ was observed in the sample.

For the probability to observe a certain category count $(n_1, \ldots, n_k) = \mbf{n}$,
we have to account for the different possible orderings in $\mbf{x}$ leading to the same count vector $\mbf{n}$.
Therefore,
\begin{align}\label{eq:multinomdens}
f_\theta(\mbf{n}) &= \binom{n}{n_1,\ldots,n_k} \prod_{j=1}^k \theta_j^{n_j}
                   = \frac{n!}{n_1!\cdot \ldots \cdot n_k!} \prod_{j=1}^k \theta_j^{n_j}\,.
%             \propto \prod_{j=1}^k \theta_j^{n_j}\,.
\end{align}
As a shortcut, we write $\mbf{n} \sim \mult(\theta)$.


\section{Statistical Inference with the Bayesian Paradigm}
\label{sec:bayes-inference}

As the inference models discussed in this thesis are all based on the Bayesian approach to statistical inference,
we will now give a short introduction to the basic principles of Bayesian inference.

The Bayesian approach allows (possibly subjective) knowledge on the parameter $\vartheta$ to be expressed by a probability distribution on%
\footnote{Again we implicitly assume that $\Theta$ is complemented by an appropriate $\sigma$-field $\sigma(\Theta)$.}
$\Theta$, with probability mass or density function $p(\vartheta)$ called \emph{prior distribution}.
Interpreting the elements $f_\vartheta(x)$ of the sampling model as conditional distributions of the sample given the parameter,
denoted by $f(\mbf{x}\mid\vartheta)$ and called \emph{likelihood},
turns the problem of statistical inference into a problem of probabilistic deduction,
where the \emph{posterior distribution}, i.e.\ the distribution of the parameter given the sample data,
can be calculated by Bayes' Rule.%
\footnote{Donald Gillies \cite{1987:gillies, 2000:gillies} argues that Bayes' Theorem was actually developed
in order to confront the problem of induction as posed by Hume \cite{1739:hume}.}
Thus, in the light of the sample $\mbf{x}= (x_1, \ldots, x_n)$ the prior distribution is updated by Bayes' Rule
to obtain the posterior distribution with density or mass function
\begin{align}
\label{eq:bayesrule}
p(\vartheta\mid\mbf{x}) \propto f(\mbf{x}\mid\vartheta) \cdot p(\vartheta)\,.
\end{align}
The posterior distribution is understood as comprising all the information from the sample and the prior knowledge.
It therefore underlies all further inferences on the parameter $\vartheta$,
like point estimators, interval estimators,
or the \emph{posterior predictive distribution},
which is the distribution of further observations based on $p(\vartheta\mid\mbf{x})$
(see Eq.~\eqref{eq:posteriorpredictive} below).


\subsection{Regular Conjugate Families of Distributions}

Traditional Bayesian inference is frequently based on so-called \emph{conjugate priors} related to a specific likelihood.
Such priors have the convenient property that the posterior resulting from~\eqref{eq:bayesrule}
belongs to the same class of parametric distributions as the prior, and thus only the parameters have to be updated,
which makes calculation of the posterior and thus the whole Bayesian inference easily tractable.

Fortunately, there are general results guiding the construction of conjugate priors in models used most frequently in practice,
namely in the case where the sample distribution belongs to a so-called \emph{(regular) canonical exponential family}
\cite[pp.~202 and 272f]{2000:bernardosmith}. %Def.~4.12 and Prop.~5.6
This indeed covers many sample distributions relevant in a statistician's everyday life,
like Normal and Multinomial models, Poisson models, or Exponential and Gamma models.
After presentation of the general framework, we will discuss its instantiation for the Normal
and the Multinomial sampling models as introduced in Sections~\ref{sec:normaldist} and \ref{sec:multinomdist} above.

A sample distribution
(from now on understood directly as the distribution $p_\vartheta^{\otimes n}$ of an i.i.d.\ sample $\mbf{x}$ of size $n$)
is said to belong to the \emph{(regular) canonical exponential family} if its density or mass function satisfies the decomposition
\begin{align}\label{eq:expofam-sampledens}
f(\x \mid \theta) &\propto \exp\big\{\langle \psi, \tau(\x) \rangle - n \mbf{b}(\psi)\big\}\,,
\end{align}
where $\psi \in \Psi \subset \reals^q$ is a transformation of the (possibly vectorial) parameter $\theta \in \Theta$,
and $\mbf{b}(\psi)$ a scalar function of $\psi$ (or, in turn, of $\theta$).
$\tau(\x)$ is a function of the sample $\x$ that fulfills $\tau(\x) = \sum_{i=1}^n \tau^*(x_i)$,
with $\tau^*(x_i) \in \mathcal{T} \subset \reals^q$,
while $\langle\cdot, \cdot\rangle$ denotes the scalar product.
From these ingredients, a conjugate prior on $\psi$ can be constructed as%
\footnote{In our notation, ${}\uz$ denotes prior parameters; ${}\un$ posterior parameters.}
\begin{align}\label{eq:canonicalprior}
p(\psi \mid \nz, \yz) \dd\psi
 &\propto \exp\Big\{ \nz \Big[ \langle \yz, \psi \rangle - \mbf{b}(\psi) \Big] \Big\} \dd\psi\,,
\end{align}
where $\nz$ and $\yz$ are now the parameters by which a certain prior can be specified.
The domain of $\yz$ is $\Y$, the interior of the convex hull of $\mathcal{T}$;
$\nz$ must take strictly positive values for the prior to be proper (integrable to $1$).

An interpretation for these parameters will be given shortly.
First, let us calculate the posterior density for $\psi$.
The prior parameters $\yz$ and $\nz$ are updated to their posterior values $\yn$ and $\nn$ in the following way:
\begin{align}\label{eq:canonicalupdate}
\yn &= \frac{\nz}{\nz + n} \cdot \yz + \frac{n}{\nz + n} \cdot \frac{\tau(\x)}{n}\,, &
\nn &= \nz + n\,,
\end{align}
such that the posterior can be written as
\begin{align}\label{eq:canonicalposterior}
p(\psi \mid \x, \nz, \yz)
 =: p(\psi \mid \nn, \yn)
 &\propto \exp\Big\{ \nn \Big[ \langle \yn, \psi \rangle - \mbf{b}(\psi) \Big] \Big\} \dd\psi\,.
\end{align}
In this setting, $\yz$ and $\yn$ can be seen as the parameter describing the main characteristics of the prior and the posterior,
and thus we will call them \emph{main prior} and \emph{main posterior parameter}, respectively.
$\yz$ can also be understood as a prior guess for the random quantity $\ttau(\x) := \tau(\x)/n$ summarizing the sample,
as $\E[\ttau(\x) \mid \psi] = \nabla\mbf{b}(\psi)$,
where in turn $\E[\nabla\mbf{b}(\psi) \mid \nz, \yz] = \yz$ \cite{2000:bernardosmith}***more concrete***.

Characteristically, $\yn$ is a weighted average of this prior guess $\yz$ and the sample `mean' $\ttau(\x)$,
with weights $\nz$ and $n$, respectively.%
\footnote{This weighted average property of Bayesian updating with conjugate priors is an important issue
we comment on ***later / in Section~\ref{}***.}
Therefore, $\nz$ can be seen as ``prior strength'' or ``pseudocounts'',
reflecting the weight one gives to the prior as compared to the sample size $n$.
To make this more explicit, $\nz$ can be interpreted as the size of an imaginary sample
that corresponds to the trust on the prior information in the same way
as the sample size of a real sample
corresponds to the trust in conclusions based on such a real sample \cite[p.~258]{Walter2009a}.

The posterior $p(\psi \mid \nn, \yn)$ can be transformed back to a distribution on $\theta$
in order to deal with a commonly known parameter or distribution family for it
(as we will do in Section~\ref{}*** below.)
Besides the posterior itself, also the posterior predictive distribution
\begin{align}
\label{eq:posteriorpredictive}
f(\x^*\mid\x) &= \int f(\x^* \mid \psi) p(\psi \mid \nn, \yn) \dd\psi\,,
\end{align}
a distribution on future samples $\x^*$ after having seen a sample $\x$,
forms the basis for the different inference tasks. %as listed in Section~\ref{inference:sec:basictasks}.
Next, we will thus briefly describe a systematic of inference tasks.


\subsection{Inference Tasks}
\label{sec:inferencetasks}

We may structure the different inference tasks by
the type of statement one wants to infer from the data.
As such, this systematic is not exclusive to Bayesian inference methods,
and neither to the parametric models considered in Section~\ref{sec:parametricmodels},
but it will be formulated in terms of parameters in a Bayesian setting here.

We distinguish two groups of inferences, namely
\begin{enumerate}
\item static conclusions and
\item predictive conclusions.%
%\footnote{Static conclusions are still more common in statistical applications.
%In the light of the success of procedures from machine learning in statistics, the predictive view,
%early propagated, e.g., by \cite{1993:geisser}, has attracted increasing attention.}
\end{enumerate}

\emph{Static conclusions} refer directly to properties of the sampling model, typically to its parameter(s).
The following procedures, which are based directly on the posterior \eqref{eq:canonicalposterior} in the Bayesian paradigm,
are the most common:
\begin{enumerate}
\item[1a)] \emph{Point estimators},
where a certain parameter value is selected to describe the sample.
\item[1b)] \emph{Interval estimators},
where the information is condensed in a certain subset of the parameter space $\Theta$, typically in an interval when $\Theta \subseteq \reals$.
\item[1c)] \emph{Hypotheses tests},
where the information in the sample is only used to decide between two mutually exclusive statements called \emph{hypotheses},
usually denoted by $H_0$ and $H_1$.
\item[1e)] \emph{Decision making},
where, more generally, the conclusion may be to select certain utility maximizing or loss minimizing acts from a set of possible acts.
Indeed, all three tasks listed before can be formally understood as a special case of decision making,
by considering an appropriate set of acts and a loss function fitting the inferential objective.
We will flesh this out to some extent in the examples below***.%
\footnote{For more details, see, e.g., ******.}
\end{enumerate}

\emph{Predictive conclusions} instead summarize the information by statements on properties of typical further units,
either by describing the whole distribution (as with the posterior predictive \eqref{eq:posteriorpredictive},
or by certain summary measures.
Similar to static conclusions, one can thus consider, e.g.,
\begin{enumerate}
\item[2a)] \emph{Point prediction},
where a certain sample value is selected as the most likely to occur.
This is especially useful in the case of discrete sampling distributions,
where this procedure amounts to classification of further sample units.
\item[2b)] \emph{Interval prediction},
where instead a certain subset of the sample space $\mathcal{X}$ is determined,
into which furter sample units are like to fall.
An example are prediction bands in regression analysis.
\end{enumerate}

The concretion of this framework for Bayesian inference with regular conjugate priors
is now demonstrated for the sampling models presented in Sections~\ref{sec:normaldist} and \ref{sec:multinomdist}.
As a first simple example, we will consider inference in the Binomial model,
being the special case of the Multinomial model with only two categories.
Then, we will briefly turn to the Normal model,
before we present the more complex considerations for the Multinomial model with $k>2$ categories.
The latter model %for the Multinomial model (Section~\ref{sec:multinomdist})
is then used for inferences in common-cause modeling,
which will serve as a real-world example illustrating the powers and shortcomings of standard Bayesian inference,
ultimately motivating the shift to imprecise Bayesian inference.


\subsection{The Beta-Binomial Model}
\label{sec:beta-binom}

As the special case of the multinomial model \eqref{eq:multinomdens} with only two categories, we will consider the Binomial model
\begin{align}
\label{eq:binomdens}
f(\x\mid\theta) &= {n \choose s}\theta^s (1-\theta)^{n-s}\,,
\end{align}
where $\x$, the vector of $n$ observations, is composed of scalar $x_i$'s being either $0$ or $1$
denoting `failure' or `success' in an experiment with these two outcomes.
$s = \sum_{i=1}^n x_i$ is the number of successes,
and the (unknown) parameter $\theta \in (0,1)$ is the probability for `success' in a single trial.
\eqref{eq:binomdens} can be written in the canonical exponential family form \eqref{eq:expofam-sampledens}:
\begin{align*}
f(\x\mid\theta) &\propto \exp\Big\{ \log\Big(\frac{\theta}{1-\theta}\Big) s - n \big(-\log(1-\theta)\big) \Big\}
\end{align*}
We have thus $\psi = \log(\theta/(1-\theta))$, $\mbf{b}(\psi) = -\log(1-\theta)$, and $\tau(\x) = s$.

From these ingredients, a conjugate prior on $\psi$ can be constructed along \eqref{eq:canonicalprior},
leading here to
\begin{align*}
p\Big(\log\Big(\frac{\theta}{1-\theta}\Big) \mid \nz, \yz\Big) \dd\psi %\dd\log\big(\frac{\theta}{1-\theta}\big)
 &\propto \exp\Big\{ \nz \Big[ \yz \log\Big(\frac{\theta}{1-\theta}\Big) + \log(1-\theta) \Big] \Big\} \dd\psi\,.
 %\dd\log\big(\frac{\theta}{1-\theta}\big)\,.
\end{align*}
This prior, transformed to the parameter of interest $\theta$,
\begin{align*}
p(\theta\mid \nz, \yz)\dd\theta &\propto \theta^{\nz\yz - 1} (1-\theta)^{\nz(1-\yz) - 1} \dd\theta\,,
\end{align*}
is a Beta distribution with parameters $\nz\yz$ and $\nz(1-\yz)$, in short, %$\theta \sim \Be(\nz\yz, \nz(1-\yz))$.
\begin{align*}
\theta &\sim \be(\nz\yz, \nz(1-\yz))\,.
\end{align*}

The combination of a Binomial sampling model with this conjugate Beta prior is called \emph{Beta-Binomial Model}.
Here, $\yz = \E[\theta]$ can be interpreted as prior guess of $\theta$,
while $\nz$ governs the concentration of probability mass around $\yz$.
Due to conjugacy, the posterior on $\theta$ is a $\be(\nn\yn, \nn(1-\yn))$,
where the posterior parameters $\nn$ and $\yn$ are given by \eqref{eq:canonicalupdate}.

A \textbf{point estimator} for $\theta$ can be extracted from the posterior distribution $p(\theta\mid\x)$
by considering $\Theta$ as the set of possible acts, and choosing a \emph{loss function}.
The loss function $l$ gives a functional form of the severity of deviations of an estimator to its goal;
here, it values the distance of a point estimator $\hat{\theta}$ to $\theta$.
The \emph{quadratic loss function} $l(\hat{\theta}, \theta) = (\hat{\theta}-\theta)^2$
values small deviations relatively low, whereas large deviations are given a high weight.
As can be shown (see, e.g., \cite[p.~352f]{2002:casella}),
the quadratic loss function leads to the posterior expectation as the Bayesian point estimator.
Here, $\E[\theta\mid\x] = \yn$, and so the posterior expectation of $\theta$ is a weighted average
of the prior expectation $\E[\theta] = \yz$ and the sample proportion $s/n$, with weights $\nz$ and $n$, respectively.
Taking the \emph{absolute loss function} $l(\hat{\theta}, \theta) = |\hat{\theta}-\theta|$
leads to the median of the posterior distribution as the point estimator.
Here, $\med(\theta\mid\x)$ has no closed form solution, and must be determined numerically.
The \emph{indicator loss function}
\begin{align*}
l(\hat{\theta}, \theta) = \begin{cases} 0 & |\hat{\theta}-\theta| \le \epsilon \\ 1 & \text{else}\end{cases}\,,
\end{align*}
for $\epsilon \rightarrow 0$, leads to the maximum of the posterior,
often abbreviated as MAP (maximum a posteriori) estimator \cite[\S 5.1.5, p.~257]{2000:bernardosmith}.
For a $\be(\nn\yn, \nn(1-\yn))$, the mode is
\begin{align*}
\mode \pi(\theta\vert\mbf{x}) &= \frac{\nn\yn - 1}{\nn - 2} = \frac{\nz\yz - 1 + s}{\nz - 2 + n}\,,
\end{align*}
and thus is a weighted average of the prior mode $\frac{\nz\yz - 1}{\nz -2}$ $(\nz > 2)$
and the sample proportion $s/n$, with weights $\nz - 2$ and $n$, respectively.

In the Bayesian approach, \textbf{interval estimation} is rather simple,
as the posterior distribution delivers a direct measure of probability for arbitrary subsets of the parameter space $\Theta$.
Mostly, so-called \emph{highest posterior density} (HPD) intervals are considered,
where for a given probability level $\gamma$ the shortest interval covering this probability mass is calculated.
For unimodal densities, this is equivalent to finding a threshold $\alpha$ such that
the probability mass for all $\theta$ with $p(\theta\mid\x) \ge \alpha$ equals $\gamma$, hence the name.
(See, e.g., \cite[\S 5.1.5, pp.~259f]{2000:bernardosmith}.)
For the Beta posterior, a HPD interval for $\theta$ must be determined by numeric optimization.
For approximately symmetric (around $\frac{1}{2}$) Beta posteriors, a good approximation is the symmetric credibility interval,
delimited by the $\frac{1-\gamma}{2}$ and the $\frac{1+\gamma}{2}$ quantile of the posterior.

The \textbf{testing of hypotheses} concerning the parameter of interest $\theta$ can be done
by comparing posterior probabilities of two subsets of the parameter space, which are usually denoted by $H_0$ and $H_1$.
High values of $P(H_1\mid\x) / P(H_0\mid\x)$ then indicate high plausibility of $H_1$ as compared to $H_0$.

The \textbf{posterior predictive} distribution, giving the probability for $s^*$ successes in $n^*$ future trials
after having seen $s$ successes in $n$ trials, is
\begin{align*}
f(s^* \mid s) &= {n^* \choose s^*} \frac{\B\big(s^* + \nn \yn, n^* - s^* + \nn (1 - \yn)\big)}{\B\big(\nn\yn, \nn (1 - \yn)\big)}\,,
\end{align*}
known as the \emph{Beta-Binomial distribution}.

